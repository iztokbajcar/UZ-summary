\documentclass{article}

\usepackage{amsmath}
\usepackage{hyperref}

\author{ib8548}
\title{
    UZ summary \\
    \large Summary of the Machine Perception course lectures at FRI
}

\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage

\section{Image processing}

Processing steps:
\begin{enumerate}
    \item Convert gray image to binary image \textbf{(thresholding)}
    \item Clean binary image \textbf{(morphologic filtering)}
    \item Extract individual regions \textbf{(connected components)}
\end{enumerate}

    \subsection{Thresholding}
    Otsu's algorithm:
    \begin{enumerate}
        \item Separate the pixels into two groups by intensity threshold $T$
        \item For each group get an average intensity and calculate $\sigma^{2}_{between}$
        \item Select the $T$ that maximizes the variance: \\
                  $T^* = argmax_T[ \sigma^{2}_{between}(T) ]$
    \end{enumerate}

    \subsection{Cleaning the image}
    
        \subsubsection{Fitting and hitting}
        \textbf{Fitting:} all ``1'' pixels in the SE (structuring element) cover all ``1'' pixels in the image \\ 
        \textbf{Hitting:} at least one ``1'' pixel in the SE covers a ``1'' pixel in the image

        \subsubsection{Erosion}
        \begin{itemize}
            \item Reduces the size of structures
            \item Removes bridges, branches, noise
            \item $g(x, y) = 
            \begin{cases}
                1 \text{ if } s \text{ fits } f \\
                0 \text{ otherwise }
            \end{cases}$
        \end{itemize}

        \subsubsection{Dilation}
        \begin{itemize}
            \item Increases the size of structures
            \item Fills holes in regions
            \item $g(x, y) =
            \begin{cases}
                1 \text{ if } s \text{ hits } f \\
                0 \text{ otherwise }
            \end{cases}$
        \end{itemize}

        \subsubsection{Opening}
        \begin{itemize}
            \item \textbf{Erosion} followed by \textbf{dilation}
            \item Removes small objects, preserves rough shape
            \item Filters out structures depending on the size and shape of the structuring element
        \end{itemize}

        \subsubsection{Closing}
        \begin{itemize}
            \item \textbf{Dilation} followed by \textbf{erosion}
            \item Fills holes, preserves rough shape
        \end{itemize}

    \subsection{Labelling regions}

        \subsubsection{Sequential connected components}
        \begin{itemize}
            \item Process image from left to right, from top to bottom:
            \begin{enumerate}
                \item If the current pixel value is 1
                \begin{enumerate}
                    \item If only one neighbor \textbf{(left or top)} is 1, copy its label
                    \item If both neighbors are 1 and have the same label, copy the label
                    \item If they have different labels:
                    \begin{itemize}
                        \item Copy label from the left
                        \item Update the table of equivalent labels (remember that the label of the left neighbor represents the same connected component as the label of the top neighbor)
                    \end{itemize}
                    \item Otherwise form a new label
                \end{enumerate}
            \end{enumerate}
            \item Relabel with the smallest equivalent labels
        \end{itemize}

    \subsection{Color}

    \begin{itemize}
        \item Additive models
        \item Subtractive models
    \end{itemize}

        \subsubsection{Color spaces}
        \begin{itemize}
            \item Role: unique color specification
            \item A color space is defined by the choice of primary colors (primaries)
        \end{itemize}
                \subsubsection{Non-uniform color spaces}
                \begin{itemize}
                    \item If two colors are close to each other (by Euclidean distance), it \textbf{doesn't mean that they are similar perceptually}
                    \item CIE XYZ --- linear
                    \item RGB --- linear
                    \item HSV --- nonlinear
                \end{itemize}

                \subsubsection{Uniform color spaces}
                \begin{itemize}
                    \item CIE Lab
                    \item CIE u'v'
                \end{itemize}

        \subsection{Color description by using histograms}
        \begin{itemize}
            \item Histograms record the frequency of intensity levels \\
                  $h(i) = \text{ the number of pixels in } I \text{ with the intensity value } i$
            \item Color histogram is a robust representation of images (robust to changes in translation, scale and partial occlusion)
        \end{itemize}

        \subsection{Filtering}
        \begin{itemize}
            \item Noise reduction and image restoration
            \item Structure extraction/enhancement
        \end{itemize}

            \subsubsection{Types of noise}
            \begin{itemize}
                \item Gaussian noise
                \item Salt and pepper noise
                \item Impulse noise
            \end{itemize}

            When chaining \textbf{linear} filters, the order \textbf{doesn't matter}.
            When chaining \textbf{nonlinear} filters (e.g.\ the median filter), the order \textbf{does matter}.

        \subsection{Linear filtering as template matching}
        \begin{itemize}
            \item If we correlate the image with a template, we get a map of the template's similarity to the image
            \item The max value of the map is the location of the template in the image
            \item To account for the scale dissimilarities, we can start with the original version of our image, correlate with the template, scale the image \textbf{down} (subsample) and repeat the process --- \textbf{image pyramid}
            \item \textbf{Smoothing} the image before subsampling removes the features that couldn't be reconstructed in the subsampled image because of \textbf{antialiasing}
        \end{itemize}
    
        \newpage
\section{Derivatives and edge detection}

    \subsection{Image derivatives}

    Implementation by convolution:
    \begin{itemize}
        \item \textbf{Horizontal derivative:} 
        \begin{itemize}
            \item $ \frac{\partial{f}(x, y)}{\partial{x}} \approx \frac{f(x+1, y) - f(x, y)}{1}$
            \item kernel:
            $\begin{bmatrix}
                -1 & 1
            \end{bmatrix}$
        \end{itemize}

        \item \textbf{Vertical derivative:} 
        \begin{itemize}
            \item $ \frac{\partial{f}(x, y)}{\partial{y}} \approx \frac{f(x, y+1) - f(x, y)}{1}$
            \item kernel:
            $\begin{bmatrix}
                -1 \\
                 1
            \end{bmatrix}$
        \end{itemize}

        \item \textbf{Image gradient:}
        \begin{itemize}
            \item $\nabla{f} = 
            \begin{bmatrix}
                \frac{\partial{f}}{\partial{x}}, \frac{\partial{f}}{\partial{y}}
            \end{bmatrix}$
            \item It points in the direction of greatest intensity change
            \item Gradient direction: $\theta = \arctan{(\frac{\partial{f}}{\partial{y}} / \frac{\partial{f}}{\partial{x}})}$
            \item Gradient strength (magnitude): $\sqrt{(\frac{\partial{f}}{\partial{x}})^2 + (\frac{\partial{f}}{\partial{y}})^2}$
        \end{itemize}
    \end{itemize}

    Because derivation amplifies the noise in the image, we usually smooth the image using a \textbf{2D Gaussian filter}:
    \begin{itemize}
        \item $I \rightarrow I * (\frac{\partial{G}}{\partial{x}})$
        \item The kernel size determines which structures are preserved: \textbf{bigger} Gaussian kernels detect edges on a \textbf{bigger} scale.
    \end{itemize}

    \subsection{Edge detection}
    The basic idea: find \textbf{strong gradients}, then post-process \\
    Criteria for an \textbf{optimal edge detector}:
    \begin{itemize}
        \item \textbf{Good detection:} minimizing the probability of false positives and false negatives
        \item \textbf{Good localization:} detecting edges close to their true location
        \item \textbf{Specificity:} minimizing the number of local maxima around the true edge (returning a single point per true edge)
    \end{itemize}

        \subsubsection{Canny edge detector}
        \begin{enumerate}
            \item Filter image by a \textbf{derivative of a Gaussian}
            \item Calculate the gradient \textbf{magnitude} and \textbf{orientation}
            \item \textbf{Thin} potential edges to a single pixel thickness \\
            \textbf{Non-maxima suppression} --- for each pixel, check if it is a local maximum along its gradient direction. If it is not, set it to zero in the modified image.
            \item Select sequences of connected pixels that are likely an edge \\
            \textbf{Hysteresis} --- choose two thresholds, $t_{low}$ and $t_{high}$. Discard all pixels below $t_{low}$ and retain pixels that are above $t_{high}$ or connected into a component that contains at least one pixel above $t_{high}$.
        \end{enumerate}

        \noindent
        
    \subsection{Edge detection by parametric models}

        \subsubsection{Hough Transform}
        \begin{enumerate}
            \item For each edge point compute parameters of all possible lines passing through that point
            \[
                x \cos{\vartheta} + y \sin{\vartheta} = \rho
            \]
            \item Cast a vote for each set of parameters (e.g.\ store votes inside an accumulator array)
            \item Select the lines that recieve enough votes (i.e.\ elements of the accumulator array with the highest/high enough values)
        \end{enumerate}
        Extensions:
        \begin{itemize}
            \item Use the gradient direction \\
                  $\vartheta$ = gradient direction at $(x, y)$
            \item Assign higher weight (in votes) to points with large edge magnitude
                  (instead of $H[\rho, \vartheta] \text{ += } 1$ use $H[\rho, \vartheta] \text{ += } m(x, y)$)
        \end{itemize}
        
        \fbox{\parbox{\textwidth}{

            \noindent Pros:
            \begin{itemize}
                \item Each point is processed independently:
                \begin{itemize}
                    \item Robustness to partial occlusion
                    \item Highly parallelizable
                \end{itemize}
                \item Robustness to noise
                \item Can detect multiple instances of a single model in one pass
            \end{itemize}

            \noindent Cons:
            \begin{itemize}
                \item Time complexity increases exponentially with the number of free \\ parameters
            \end{itemize}

        }}

    \newpage

\section{Fitting parametric models}
\[ \mathbf{x}_i' = f(\mathbf{x}_i ; \mathbf{p}) \]
\[ \mathbf{x}_i' = \mathbf{R} \mathbf{x}_i + \mathbf{T} \]

\begin{itemize}
    \item Example: transform $\mathbf{x}_i$ into $\mathbf{x'}_i$ by a function $f(\mathbf{x;p})$
    \item Inverse problem: \textbf{find the transformation parameters} based on a set of correspondences --- best values for $\mathbf{p}$
    \item Best parameter values: those that \textbf{minimize} the \textbf{projection error}
\end{itemize}

\textbf{TODO} least squares

    \subsection{RANSAC}
    (\textbf{Ran}dom \textbf{Sa}mple \textbf{C}onsensus)
    \begin{enumerate}
        \item Randomly select the smallest group of correspondences from which we can estimate the parameters
        \item Fit the parametric model to the selected correspondences (e.g.\ by the least squares method)
        \item Project all other points and count the number of inliers
        \item Remember the parameters that maximize the number of inliers
    \end{enumerate}

    \noindent Parameters:
    \begin{itemize}
        \item \textbf{Threshold} for identifying the inliers (chosen in a way that we achieve the desired probability of an inlier falling below the threshold)
        \item The number of \textbf{sampling iterations}
    \end{itemize}
    We typically need as many correspondences as there are parameters for our model. \\

    \fbox{\parbox{\textwidth}{
        \noindent Pros:
        \begin{itemize}
            \item Very simple and general
            \item Applicable to many real-life problems
            \item Often used in practice
        \end{itemize}

        \noindent Cons:
        \begin{itemize}
            \item We need to decide on the parameters
            \item Finding the optimum may require many iterations
            \item Fails at a very small number of inliers
        \end{itemize}
    }}
        
\end{document}
